* Some tree related routines

* Ramblings
  I hope to write up something more easily digestible but for now just doing a bit of a brain dump.

  Since K has nested vectors (lists) you could always represent trees in a Lisp-y way.  I.e.
  ~(root; ((leftchld; leaf); (rightchld; leaf)))~ where a node is ~(value; (children))~ and a leaf
  is somehow distinguishable from a non-leaf by being say an atom.

  There are some slightly annoying aspects to this, though.  For one, you need a convention to
  distinguish leaves from interior nodes.  For another to access interior nodes you need to descend
  the tree.  Sure, nine times out of ten when you're working with trees you're having to walk the
  tree, but still.  Lastly, nested lists mean pointers of pointers which just doesn't feel very
  array-like.

  What can be done?  Well there are [[https://github.com/JohnEarnest/ok/blob/gh-pages/docs/Trees.md][other representations of trees]], but the one I prefer is what I
  like to call an [[http://nsl.com/k/tableaux/trees.k][Apter tree]].  You can find examples on [[http://nsl.com][nsl.com]] or this article from
  [[http://archive.vector.org.uk/art10500340][Vector magazine]], but depending on your appetite this may not feel like enough of a description
  of how they work.

  [DISCLAIMER: I haven't done much(any?) research into the history of this data structure but I've
  also not run into anyone else who has.]

** Apter trees
   The basic idea is to separate the /structure/ of tree from its /contents/.  By "structure" we mean
   which nodes are connected to which other nodes.  While it might seem natural to do this with a
   dictionary of node -> list of children this brings us back to nested lists.  Here's where a neat
   observation comes in.

   : While each node can have multiple children, each node (except the root) has only /one/ parent.

   Thus if we have a tree such as ~(15;(12 9;18 2))~, then the parent of the leaf ~9~ is ~12~ and the parent
   of the ~12~ is ~15~.  Note that even here there's a bit of awkwardness.  Is ~12~ a node or is it a value?
   Similarly for ~9~.

   Let's give each node an index using a depth first preorder of the tree.  So we have 5 nodes whose
   indices are ~0 1 2 3 4~ and whose values are ~15 12 9 18 2~.  Now we can say that the parent of node
   ~2~ is ~1~ and the parent of node ~1~ is ~0~.  So using ~0N~ for the parent of the root (for now),
   the parent of each node is ~0N 0 1 0 3~.  Now we have a /"parent vector"/ and a /"values vector"/.
   If nothing else this clears up the confusion of which we're talking about.

   Note that there's nothing really special about using depth first preorder.  If we shuffled the indices,
   we'd simply need to shuffle the indices of each parent to point to its new location.  What /is/ important
   is that the parent vector and the values vector be in the /same order/.  Any ordering would faithfully
   represent the tree, but conventions are useful.

   Let's give these names ~p:0N 0 1 0 3~ and ~n:15 12 9 18 2~.  So the value of our node at index ~2~ is
   ~n[2]~9~ and its parent is at index ~p[2]~1~.  The value of the parent is ~n[p[2]]~12~ and the parent
   of the parent at index ~2~ is ~p[p[2]]~0~.  But we're using an array language!  We can do this across
   all the indices simultaneously. ~p[!#p]~0N 0 1 0 3~ and ~p[p[!#p]]~0N 0N 0 0N 0~.  This last could also
   be written ~2(p@)/!#p~.

   We could also look at the fixed point scan which gives a matrix whose columns give paths from each index
   up to the /parent/ of the root, which is currently marked with ~0N~

	:  (p@)\!#p
	: (0 1 2 3 4
	:  0N 0 1 0 3
	:  0N 0N 0 0N 0
	:  0N 0N 0N 0N 0N)

   While this works well enough for many circumstances its more useful to stop at the root.  To make this
   happen we make the root /self-parenting/.  I.e. we define our parent vector to be ~p:0 0 1 0 3~.

	:  (p@)\!#p
	: (0 1 2 3 4
	:  0 0 1 0 3
	:  0 0 0 0 0)

*** Depth vectors
    Above we basically eyeballed the parent vector.  How do we generate a parent vector more generally?
	This of course depends on the information we're given, but often it's easiest to first shoot for a
	slightly different representation.  That is a depth vector.

	The depth vector is simply the length of each path from a leaf up to the parent.

	I.e.

	 :  +/1&(p@)\!#p:0^p
	 : 0 1 2 1 2

	Generally it's easier to generate a depth vector than to directly generate a parent vector.  For
	instance ~d:{$[`i=@y;x;,/x,o[x+1]'y 1]}[0;(15;(12 9;18 2))]~ or ~+\-/"()"=\:"(a(bc(d)ef))"~.  (We'll
	talk more about this second in a bit.)

	Okay, let's assume depth vectors are easy to come by.  How does this help us create a parent vector?
	Here's where conventions help out.  If our depth vector is depth first preorder then we know that our
	parent is at the index /"closest to the left at depth one less than ours"/.  This is calculable!  There
	are different approaches to doing this calculation, but let's start with the easiest.

	:  {|/0,&x=-1+*|x}',\d
    : 0 0 1 0 3

   Okay so now let's say we have a parent vector and a node vector, what can we do with them?  Well, we
   can do things like ask which index is the parent of the node with value ~9~?  We can simply do ~p[n?9]~.
   Notice that we didn't have to walk the tree to find this!!

   But what if we did want to walk the tree?  That's still an option.  We just need to find children of
   each parent vector.  We can use "group" to do that ~=p~.  Here, having the root being self-parenting
   can be a bit of pain since we want to recurse to proper children and not enter an infinite loop.
   With simple trees like this we can just do ~=0N,1_p~ to effectively make our root a child of some
   /other node/ we'll never refer to.  There's also another little trick to get a useful prototype.
   Let's use ~chld:(=0N,1_p),(,0N)!,!0~ as our map from parents to children.  Then ~chld[0]~1 3~ and
   ~chld[2]~ is ~!0~.

   Now we can do the following to descend the tree:

   :  chld:(=0N,1_p),(,0N)!,!0
   :  {(x@z;o[x;y]'y@z)}[n;chld]0
   : (15
   :  ((12;,(9;()));(18;,(2;()))))

   (Here leaves have empty children, but this is simply an example of what's possible.)


*** Sure, but why?
    Fair question.  Well posed.  My motivation was mostly to see what's possible with a data structure
	I wasn't familiar with, but if you keep your eye out for it similar structures pop up in other
	domains.  The motivation is usually that by using vectors you get the benefit of data locality.
	I.e. you're likely to have related items accessed together hot in the cache.  On the negative side,
	as is common with vector structures, modifying them means moving them in bulk to ensure that they're
	in contiguous memory.  Thus they really shine when the size of the structure is relatively stable.

	Weighing the benefits in not unlike comparing linked lists to arrays.  Each node in a linked list
	might be stable in memory at the expense of data locality whereas you may need to moved arrays around
	if you need to ensure data locality.

	Apter trees may not be right for your application, but in my experience they have their good points.
	To my mind separating the structure from the content reduces some mental load.  I find it easier to
	picture the kind of manipulations that are possible and how to accomplish them.

	If you're still curious at this point, read on...

*** Applications
    Obviously, Apter trees being trees means they're useful whereever trees are useful.  But let's
	explore a few examples, starting with the string parsing above.

	This algorithm for finding the [[https://dl.acm.org/doi/pdf/10.1145/800136.804466][depth of parenthesization]] is a classic.  I first read about it in a
	quote from Alan Perlis speaking about how he was amazed that APL could do something so useful with
	so few characters.  Let's have a look at it again.

	:  +\-/"()"=\:"(a(bc(d)ef))"
	: 1 1 2 2 2 3 3 2 2 2 1 0

	It may be easier to match each character with it's depth:

	:  +(txt;+\-/"()"=\:txt:"(a(bc(d)ef))")
	: (("(";1)
	:  ("a";1)
	:  ("(";2)
	:  ("b";2)
	:  ("c";2)
	:  ("(";3)
	:  ("d";3)
	:  (")";2)
	:  ("e";2)
	:  ("f";2)
	:  (")";1)
	:  (")";0))

	One thing to notice, is the matching close parenthesis for each open parenthesis one deeper.
	Another thing to notice is that each opening parenthesis is at the same depth as its contents.
	This is more than likely not what you want, but is easily fixable.

	:  +(txt;(-*ps)++\-/ps:"()"=\:txt:"(a(bc(d)ef))")
	: (("(";0)
	:  ("a";1)
	:  ("(";1)
	:  ("b";2)
	:  ("c";2)
	:  ("(";2)
	:  ("d";3)
	:  (")";2)
	:  ("e";2)
	:  ("f";2)
	:  (")";1)
	:  (")";0))

	For simple compilers and parsers, this basic idea forms the baseline of the parsing process.
	As above, the step from a depth vector to a parent vector and thus to a tree structure is not
	very far.

	Doing this again with something more recognizable:

	:  +(txt;d:(-*ps)++\-/ps:"()"=\:txt:"(3*(4+9))-7")
	: (("(";0)
	:  ("3";1)
	:  ("*";1)
	:  ("(";1)
	:  ("4";2)
	:  ("+";2)
	:  ("9";2)
	:  (")";1)
	:  (")";0)
	:  ("-";0)
	:  ("7";0))
	:  d
	: 0 1 1 1 2 2 2 1 0 0 0
	:  {|/0,&x=-1+*|x}',\d
	: 0 0 0 0 3 3 3 0 0 0 0

    Notice that the open parentheses become parent (i.e. interior) nodes and that everything else
	is a leaf.  Thinking about it a little bit more, we only really needed the close parentheses
	as a marker of where the corresponding open parentheses end.  They act sort of like how null
	characters act at the end of C strings.  Now that we have that structure in the parent vector,
	we no longer need these nodes.

	In general removing items from the parent vector could throw off the indices in that vector.
	Consider ~(1+3)*(4+6)~.  There is a trick for doing this, but more straightforward here is
	to edit the depth vector.  Because closed parentheses don't interupt the "closest index to the
	left at depth one less than ours", removing them doesn't effect the parent vector we'll
	generate from it.

	:   +(txt;d):(txt;d:(-*ps)++\-/ps)@\:&~*|ps:"()"=\:txt:"(3*(4+9))-7"
	: (("(";0)
	:  ("3";1)
	:  ("*";1)
	:  ("(";1)
	:  ("4";2)
	:  ("+";2)
	:  ("9";2)
	:  ("-";0)
	:  ("7";0))

	It's this sort of thinking about trees that I enjoy about Apter trees.  It's as much like
	painting as it is like programming.  Note that here we're considering ~txt~ to be the values
	vector and we make our adjustments to both the depth vector and the values vector in parallel.

	Another thing to notice here is that we have several nodes at depth ~0~.  We probably want a
	single root, though.  We could fix this by adjusting he original text and adding a set of
	parentheses around the whole thing, or we can edit this post processed tree.

	:  +("(",txt;0,1+d)
	: (("(";0)
	:  ("(";1)
	:  ("3";2)
	:  ("*";2)
	:  ("(";2)
	:  ("4";3)
	:  ("+";3)
	:  ("9";3)
	:  ("-";1)
	:  ("7";1))

	You might be asking yourself at this point "where is this going?"  The answer is "nowhere!".
	We're just playing around to see the kind of thinking that goes into working with these
	structures.


* More ramblings to come...
